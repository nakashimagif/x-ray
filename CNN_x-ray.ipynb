{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Colaboratoryで実行する場合のみ実行\" data-toc-modified-id=\"Colaboratoryで実行する場合のみ実行-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Colaboratoryで実行する場合のみ実行</a></span></li><li><span><a href=\"#前処理\" data-toc-modified-id=\"前処理-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>前処理</a></span></li><li><span><a href=\"#ニューラルネットワークの訓練\" data-toc-modified-id=\"ニューラルネットワークの訓練-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>ニューラルネットワークの訓練</a></span></li><li><span><a href=\"#ニューラルネットワークの評価\" data-toc-modified-id=\"ニューラルネットワークの評価-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>ニューラルネットワークの評価</a></span><ul class=\"toc-item\"><li><span><a href=\"#学習の進捗\" data-toc-modified-id=\"学習の進捗-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>学習の進捗</a></span></li><li><span><a href=\"#データ量とテストデータでの評価項目の関連\" data-toc-modified-id=\"データ量とテストデータでの評価項目の関連-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>データ量とテストデータでの評価項目の関連</a></span></li><li><span><a href=\"#ROC曲線\" data-toc-modified-id=\"ROC曲線-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>ROC曲線</a></span></li><li><span><a href=\"#Grad-CAM\" data-toc-modified-id=\"Grad-CAM-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Grad-CAM</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colaboratoryで実行する場合のみ実行\n",
    "- [Googleドライブの読み込みと保存](https://colab.research.google.com/notebooks/io.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import tarfile\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!mkdir images\n",
    "!mkdir logs\n",
    "\n",
    "!cp gdrive/My\\ Drive/x-ray/* .\n",
    "!cp gdrive/My\\ Drive/x-ray/images/* images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gz_list = glob.glob(\"images/*.tar.gz\")\n",
    "\n",
    "for gz_file in gz_list:\n",
    "    tar = tarfile.open(gz_file)\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "\n",
    "!pip install Keras==2.2.4\n",
    "!pip install Keras-Applications==1.0.6\n",
    "!pip install Keras-Preprocessing==1.0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pathlib\n",
    "import keras\n",
    "from keras_preprocessing.image import (array_to_img, img_to_array, load_img)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from IPython.display import display\n",
    "\n",
    "#auto relord modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(2018)\n",
    "df = pd.read_csv('Data_Entry_2017.csv', encoding='us-ascii')\n",
    "\n",
    "# Keep df where the file exist in images folder.\n",
    "file_list = glob.glob(\"images/*\")\n",
    "file_list = [os.path.basename(file) for file in file_list]\n",
    "file_list = pd.DataFrame(file_list, columns=['Image Index'])\n",
    "df = pd.merge(df, file_list, on='Image Index', how='inner')\n",
    "\n",
    "Findings = df[\"Finding Labels\"].str.split('|')\n",
    "Findings_list = [word for word_inner in Findings for word in word_inner]\n",
    "Findings_list = pd.DataFrame(Findings_list, columns=['text'])\n",
    "print(Findings_list['text'].value_counts())\n",
    "Findings_list = list(Findings_list.drop_duplicates()['text'])\n",
    "Findings_list.remove('No Finding')\n",
    "for finding in Findings_list:\n",
    "    df[finding] = Findings.apply(lambda x: 1 if finding in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create train_list.txt and validation_list.txt\n",
    "\n",
    "random.seed(2018)\n",
    "train_val_list = set([])\n",
    "with open('train_val_list.txt', 'r') as f:\n",
    "    for row in f:\n",
    "        train_val_list.add(row.rsplit()[0])\n",
    "train_list = random.sample(train_val_list, int(0.8 * len(train_val_list)))\n",
    "train_list = sorted(train_list)\n",
    "validation_list = train_val_list - set(train_list)\n",
    "validation_list = sorted(validation_list)\n",
    "with open('train_list.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(train_list))\n",
    "with open('validation_list.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(validation_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tt in ['train', 'validation', 'test']:\n",
    "    tmp_list = []\n",
    "    with open(tt + '_list.txt', 'r') as f:\n",
    "        for row in f:\n",
    "            tmp_list.append(row.rsplit()[0])\n",
    "    df[tt] = df['Image Index'].isin(tmp_list).apply(\n",
    "        lambda x: 'Y' if x == True else 'N')\n",
    "\n",
    "\n",
    "def data_split(x):\n",
    "    if x.test == \"Y\":\n",
    "        return \"test\"\n",
    "    elif x.train == \"Y\":\n",
    "        return \"train\"\n",
    "    else:\n",
    "        return \"validation\"\n",
    "\n",
    "\n",
    "df['split'] = df.apply(lambda x: data_split(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import myTrainer\n",
    "\n",
    "y_col = ['Effusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainingx = myTrainer.trainer(\n",
    "#     trainer_name='densenet_p3',\n",
    "#     dataframe=df,\n",
    "#     data_proportion=10**-2,\n",
    "#     y_col=y_col,\n",
    "#     lr=10**-7,\n",
    "#     batch_size=32,\n",
    "#     initial_epoch=0,\n",
    "#     epochs=50)\n",
    "# trainingx.lr_finder('densenet_p3')\n",
    "\n",
    "# trainingx = myTrainer.trainer(\n",
    "#     trainer_name='densenet_p2',\n",
    "#     dataframe=df,\n",
    "#     data_proportion=10**-2,\n",
    "#     y_col=y_col,\n",
    "#     lr=10**-7,\n",
    "#     batch_size=32,\n",
    "#     initial_epoch=0,\n",
    "#     epochs=50)\n",
    "# trainingx.lr_finder('densenet_p2')\n",
    "\n",
    "# trainingx = myTrainer.trainer(\n",
    "#     trainer_name='densenet_p1',\n",
    "#     dataframe=df,\n",
    "#     data_proportion=10**-1,\n",
    "#     y_col=y_col,\n",
    "#     lr=10**-7,\n",
    "#     batch_size=32,\n",
    "#     initial_epoch=0,\n",
    "#     epochs=50)\n",
    "# trainingx.lr_finder('p1')\n",
    "\n",
    "# trainingx = myTrainer.trainer(\n",
    "#     trainer_name='densenet_p0',\n",
    "#     dataframe=df,\n",
    "#     data_proportion=10**-0,\n",
    "#     y_col=y_col,\n",
    "#     lr=10**-7,\n",
    "#     batch_size=32,\n",
    "#     initial_epoch=0,\n",
    "#     epochs=50)\n",
    "# trainingx.lr_finder('densenet_p0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import myTrainer\n",
    "# training1 = myTrainer.trainer(\n",
    "#     trainer_name='densenet_lr7_p3',\n",
    "#     dataframe=df,\n",
    "#     data_proportion=10**-3,\n",
    "#     y_col=y_col,\n",
    "#     lr=10**-7,\n",
    "#     batch_size=32,\n",
    "#     initial_epoch=0,\n",
    "#     epochs=10)\n",
    "# training1.training()\n",
    "# training1.resume_training('densenet_lr7_p3_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training3 = myTrainer.trainer(\n",
    "    trainer_name='densenet_lr3_p3',\n",
    "    dataframe=df,\n",
    "    data_proportion=10**-3,\n",
    "    y_col=y_col,\n",
    "    lr=10**-3,\n",
    "    batch_size=32,\n",
    "    initial_epoch=0,\n",
    "    epochs=50)\n",
    "training3.training()\n",
    "training3.evaluating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training2 = myTrainer.trainer(\n",
    "    trainer_name='densenet_lr3_p2',\n",
    "    dataframe=df,\n",
    "    data_proportion=10**-2,\n",
    "    y_col=y_col,\n",
    "    lr=10**-3,\n",
    "    batch_size=32,\n",
    "    initial_epoch=0,\n",
    "    epochs=50)\n",
    "training2.training()\n",
    "training2.evaluating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training1 = myTrainer.trainer(\n",
    "    trainer_name='densenet_lr3_p1',\n",
    "    dataframe=df,\n",
    "    data_proportion=10**-1,\n",
    "    y_col=y_col,\n",
    "    lr=10**-3,\n",
    "    batch_size=32,\n",
    "    initial_epoch=0,\n",
    "    epochs=50)\n",
    "training1.training()\n",
    "training1.evaluating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training0 = myTrainer.trainer(\n",
    "    trainer_name='densenet_lr3_p0',\n",
    "    dataframe=df,\n",
    "    data_proportion=10**-0,\n",
    "    y_col=y_col,\n",
    "    lr=10**-3,\n",
    "    batch_size=32,\n",
    "    initial_epoch=0,\n",
    "    epochs=50)\n",
    "training0.training()\n",
    "training0.evaluating()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの評価\n",
    "## 学習の進捗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_training_log = pd.DataFrame()\n",
    "for _ in range(4):\n",
    "    tmp = pd.read_csv(\n",
    "        './logs/training_log_densenet_lr3_p' + str(_) + '.csv', sep='\\t')\n",
    "    tmp['power'] = _\n",
    "    df_training_log = pd.concat([df_training_log, tmp])\n",
    "\n",
    "vars = ['acc', 'loss', 'auc', 'fscore', 'precision', 'recall']\n",
    "epoch = df_training_log['epoch'].unique() + 1\n",
    "sns.set()\n",
    "cmap = plt.get_cmap(\"Blues\")\n",
    "for var in vars:\n",
    "    for power in range(4):\n",
    "        training = df_training_log.query('power==' + str(power))[var]\n",
    "        val = df_training_log.query('power==' + str(power))['val_' + var]\n",
    "        plt.plot(\n",
    "            epoch,\n",
    "            training,\n",
    "            'bo',\n",
    "            label=str(10**-power) + ': Training ' + var,\n",
    "            color=cmap((4 - power) / 4))\n",
    "        plt.plot(\n",
    "            epoch,\n",
    "            val,\n",
    "            'b',\n",
    "            label=str(10**-power) + ': Validation ' + var,\n",
    "            color=cmap((4 - power) / 4))\n",
    "    plt.title('Training and validation ' + var)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"logs/Effusion_Train_Val_p0-p3_\" + var + \".svg\")\n",
    "    plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for var in vars:\n",
    "    for power in [0]:\n",
    "        training = df_training_log.query('power==' + str(power))[var]\n",
    "        val = df_training_log.query('power==' + str(power))['val_' + var]\n",
    "        plt.plot(\n",
    "            epoch,\n",
    "            training,\n",
    "            'bo',\n",
    "            label='Training ' + var,\n",
    "            color=cmap((4 - power) / 4))\n",
    "        plt.plot(\n",
    "            epoch,\n",
    "            val,\n",
    "            'b',\n",
    "            label='Validation ' + var,\n",
    "            color=cmap((4 - power) / 4))\n",
    "    plt.title('Training and validation ' + var)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"logs/Effusion_Train_Val_p0_\" + var + \".svg\")\n",
    "    plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ量とテストデータでの評価項目の関連"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_log = pd.DataFrame()\n",
    "for _ in range(4):\n",
    "    tmp = pd.read_csv(\n",
    "        './logs/test_result_densenet_lr3_p' + str(_) + '.csv', sep='\\t')\n",
    "    tmp['power'] = _\n",
    "    tmp['frac'] = 10**(-_)\n",
    "    df_test_log = pd.concat([df_test_log, tmp])\n",
    "\n",
    "vars = ['acc', 'loss', 'auc', 'fscore', 'precision', 'recall']\n",
    "sns.set()\n",
    "cmap = plt.get_cmap(\"Blues\")\n",
    "#cmap = sns.cubehelix_palette(4, as_cmap=True)\n",
    "for var in vars:\n",
    "    y = df_test_log[var]\n",
    "    x = df_test_log['frac']\n",
    "    plt.plot(x, y, 'b', color=cmap(1.0))\n",
    "    plt.title('Test ' + var)\n",
    "    plt.legend()\n",
    "    plt.xscale(\"log\")\n",
    "    plt.savefig(\"logs/Effusion_Test_\" + var + \".svg\")\n",
    "    plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "roc_auc_list, fpr_list, tpr_list = training0.auc_test()\n",
    "plt.figure()\n",
    "for i, finding in enumerate(y_col):\n",
    "    fpr = fpr_list[i]\n",
    "    tpr = tpr_list[i]\n",
    "    roc_auc = roc_auc_list[i]\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        #color='darkorange',\n",
    "        lw=2,\n",
    "        label=finding + ' (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"logs/Effusion_Test_ROC.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training0.Grad_CAM('00021381_013.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training0.Grad_CAM('00001437_012.png')\n",
    "training0.Grad_CAM('00001558_016.png')\n",
    "training0.Grad_CAM('00029894_000.png')\n",
    "training0.Grad_CAM('00013337_000.png')\n",
    "training0.Grad_CAM('00021181_002.png')\n",
    "training0.Grad_CAM('00012045_009.png')\n",
    "'''\n",
    "00002395_007.png\n",
    "00027028_017.png\n",
    "00010007_168.png\n",
    "00028974_016.png\n",
    "00016291_002.png\n",
    "00023058_004.png\n",
    "00020277_001.png\n",
    "00030634_000.png\n",
    "00012834_034.png\n",
    "00018427_011.png\n",
    "00007034_016.png\n",
    "00012834_122.png\n",
    "00016972_025.png\n",
    "00023283_019.png\n",
    "00013285_026.png\n",
    "00017714_006.png\n",
    "00027631_000.png\n",
    "00020751_003.png\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 418,
   "position": {
    "height": "440px",
    "left": "1079px",
    "right": "20px",
    "top": "137px",
    "width": "762px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
